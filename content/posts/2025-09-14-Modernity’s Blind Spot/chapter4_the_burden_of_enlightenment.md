The Enlightenment of the 17th and 18th centuries marked a pivotal transformation in how humans understood themselves and the world. It gave rise to modernity: a sweeping project to rationalize our relationship with nature, to uncover objective truths, and to design a more just and orderly society through reason and empirical inquiry.

Central to this movement was the systematization of knowledge through science—a method that proved astonishingly powerful. But with that power came a burden: the ethical responsibility to wield it justly, and the need to guard against the hubris that often follows early success. These tensions will be explored in the chapters that follow.

Nowhere was the Enlightenment's triumph clearer than in the natural sciences. For the first time, we discovered that the same laws of motion applied both to apples falling from trees and planets orbiting in the heavens. This was a radical break from older paradigms, which imagined a qualitative divide between celestial and earthly phenomena. In place of myth or metaphysical speculation, we now had universal laws—precise, elegant, and predictive.

Early modern science, particularly before the development of quantum mechanics and relativity, was grounded in a profoundly deterministic worldview. It described the universe as a vast mechanism governed by precise, immutable laws—equations that could predict the motion of particles and the behavior of energy with remarkable accuracy. These laws operated independently of the observer. In fact, this independence was central to their authority: it guaranteed objectivity. The belief was simple but powerful—if an experiment were repeated under identical conditions, any observer, regardless of their perspective, would arrive at the same conclusion.

The success of modern science rests on a powerful idea: that reality can be reliably understood by eliminating personal bias, emotion, and perspective. Knowledge, in this view, becomes a process of distillation—stripping away the particular to reveal the universal. This notion formed the philosophical bedrock of the scientific method. To know the world was to adopt a disembodied vantage point, a “view from nowhere,” where truth exists independently of any observer.

## IV.1 Objectivity: A view from no here

But here lies science’s blind spot. This model presumes that such a detached and objective perspective is not only possible but also inherently superior to subjective or situated ones. It assumes that the laws science uncovers are not just useful descriptions of the world but objective truths that exist entirely “out there,” untouched by the context or limitations of the human mind.

My contention is not that these laws are false, but that they are partial. They describe models with extraordinary predictive power—but we must not mistake the map for the terrain. These models help us manipulate and navigate reality, but they are still constructs. They emerge from a particular cultural moment, from specific assumptions about what counts as knowledge, and from methodologies that necessarily foreground some aspects of the world while obscuring others.

These concerns echo the work of philosophers like **Thomas Nagel**, who famously coined the term “the view from nowhere.” In his book of the same name, Nagel challenges the idea that we can ever fully escape our own subjectivity. While he acknowledges the value of striving for objectivity, he cautions against the illusion that we can reach a truly neutral, all-seeing vantage point. Every attempt to describe reality—no matter how scientific—is necessarily filtered through human perspective, language, and conceptual frameworks.

Nagel’s argument doesn’t reject science; rather, it invites a humbler epistemology—one that recognizes objectivity as an ideal to be approached, not a place from which we can speak with divine authority. This reframing is essential: it allows us to embrace the power of scientific models without reducing all other forms of knowing—emotion, intuition, narrative, embodied experience—to mere noise.

## IV.2 Social Sciences: Modeling Humanity as Mechanism

As discussed, the success of the natural sciences gave their methods enormous prestige—so much so that early thinkers in the social sciences sought to emulate them. If physics could explain the motion of planets and particles through elegant, deterministic laws, then surely human behavior, too, could be decoded through objective observation and quantifiable patterns. The aspiration was clear: to turn the study of human beings into a rigorous science, free from ambiguity and bias.

Sociology, economics, and psychology—especially in their formative stages—borrowed heavily from the methods and metaphors of classical physics. People were modeled as rational agents, society as a system of interacting forces, and history as a chain of causes and effects. The invisible hand of the market was conceptualized as a force of nature. The dream was to predict social outcomes with the same precision that Newtonian mechanics could predict the fall of an apple.

But this ambition brought with it an inherited blind spot. By trying to strip subjectivity from their analyses, the social sciences often downplayed the very qualities that make human life distinct: inner experience, emotion, cultural meaning, and moral agency. In modeling human beings as particles in a social machine, they risked explaining away the soul in favor of systemic regularities.

This mechanistic approach helped produce useful data and powerful models—but it also shaped policy, institutions, and ideologies in ways that often left people feeling unseen or misrepresented. In treating people as objects of analysis rather than subjects of experience, the social sciences mirrored the same "view from nowhere" that defined early modern physics.

In reality, scientists do not simply uncover pre-existing truths; they actively construct the very categories through which knowledge is produced. This is the position advanced by French philosopher and sociologist Bruno Latour, who argued that scientific facts are not merely discovered but assembled through networks of practices, instruments, language, and institutional power. In this view, the observer is never neutral; the process of observation itself helps shape the outcome.

Ironically, the social sciences, in their quest to mimic the objectivity of early physics, ignored a lesson that physics itself would later reveal. Post-20th century developments—particularly in quantum mechanics and relativity—undermined the notion of a detached, objective observer. In quantum theory, the act of measurement affects the system being measured; in relativity, the position and motion of the observer fundamentally alter what is perceived. These discoveries revealed that objectivity is not the elimination of perspective, but an awareness of how perspective shapes what we take to be real.

In this light, the early social sciences were built on a paradox: they attempted to study human beings—the most subjective, interpretive, and meaning-seeking entities—by employing methods that suppressed precisely those qualities. The result was a kind of self-blindness: a framework that could quantify behavior but struggled to account for experience.

## IV.3 The Hidden Logic of Modern Life: Instrumental Reason and Its Discontents

It is worth investigating how abstract frameworks developed within the social sciences have filtered into the practical reasoning of everyday people—particularly in North American and Western European societies. These frameworks, often born as descriptive tools to better understand society, rarely remain inert. Once they enter public discourse, policy, or education, they begin to shape the very realities they were intended to observe. The social sciences, in other words, are not neutral mirrors; they are also engines of cultural influence.

This dynamic is particularly visible in the way economic models of human behavior have shaped public consciousness. Concepts like rational choice theory, cost-benefit analysis, and the notion of the self-interested actor were originally developed as analytical tools—abstractions meant to simplify complex behavior for the sake of prediction and policy design. But over time, these models have been reified, taken not merely as useful heuristics but as comprehensive truths about human nature.

The result is a quiet but profound shift in cultural expectations. These frameworks now permeate managerial culture, governance, education, and even interpersonal relationships, subtly teaching us that value lies in efficiency, that choices must be justified in terms of measurable outcomes, and that relationships—even intimate or communal ones—are transactions to be optimized. What began as a model for understanding has become a model for living.

At the heart of this shift is the rise of instrumental reason—a form of rationality concerned not with discerning what is true or good, but with calculating the most efficient means to a given end. Instrumental reason is highly effective in technical domains, but its expansion into every corner of social and moral life has narrowed our collective imagination. It frames reason as a tool for control and utility, rather than as a pathway toward wisdom, truth, or ethical discernment. In this way, reason is no longer a guide to the good life; it becomes a servant of whatever goal is set, regardless of its moral worth.

Running parallel to this development is another significant transformation: the secularization of moral life in much of North America and Western Europe. As traditional religious institutions have lost their authority, the responsibility for ethical orientation has largely been transferred to the individual. In principle, this shift promised greater freedom—autonomy of belief, emancipation from dogma. But in practice, it has often left a vacuum in our public discourse.

Questions of meaning, purpose, and moral responsibility have increasingly been relegated to the private sphere—seen as too personal, subjective, or divisive for serious public discourse. While individual autonomy is rightly respected, this retreat from shared moral reasoning has left us without a common language to explore what makes a life meaningful or a society just.

In the absence of robust ethical dialogue, public narratives are often shaped by media figures, influencers, and celebrities—voices guided more by spectacle and trend than thoughtful reflection. Core human questions—What is a good life? What do we owe each other? What does it mean to belong?—are rarely engaged in serious ways.

In their place, a minimalist ethos has taken hold: “The meaning of life is whatever one wants it to be.” While this protects freedom of belief, it also flattens public discussion. Crucially, it rests on a mistaken assumption: that subjectivity is equivalent to arbitrariness. But subjectivity is not chaos—it is the lived space of value, emotion, interpretation, and perspective. It can be reasoned with. It can be challenged, refined, and deepened through dialogue.

Yet when subjective experience is dismissed as merely private or unprovable, we lose the tools to engage it meaningfully. And this silence comes at a cost. Without shared moral conversation, cultures struggle to cultivate solidarity, purpose, or depth. Autonomy without orientation risks becoming an anxious exercise in self-construction—less liberation than isolation.

## IV.4 Irrational subjectivity

If there is one key takeaway from the previous section, it is this: subjectivity is not the enemy of reason. On the contrary, reason can—and should—serve to ground and clarify subjective experience. When it fails to do so, it leaves behind a vacuum, one that is all too often filled by irrational thinking. We see this in a variety of cultural phenomena, including:

* Conspiracy theories such as QAnon, 9/11 “inside job” narratives, and anti-vaccine movements

* Pseudoscientific health trends, from anti-GMO activism and extreme dietary ideologies to faith healing and uncritical enthusiasm for alternative medicine

* Skepticism toward public health and climate science, often driven more by ideology than evidence

* Tribalistic thinking, including extreme political partisanship, religious fundamentalism, or even fervent sports fandom that manifests in aggression or hooliganism—where identity and loyalty override reasoned judgment. 

* Pervasiveness of magical thinking, such as believing that positive affirmations alone can manifest reality, or that certain numbers, crystals, or routines hold supernatural influence

Irrationality in these cases is marked not just by a lack of evidence, but by the rejection of available evidence, or by embracing extraordinary claims while neglecting accessible methods of verification. It reflects a breakdown in epistemic discipline—a drift away from critical inquiry and toward emotionally or ideologically driven belief.

A common assumption among many educated liberals is that secularization naturally fosters a more rational society—one grounded in science, evidence, and individual autonomy. Yet this optimism often overlooks how, in the absence of shared moral and epistemic frameworks, secular cultures remain vulnerable to irrational beliefs, conspiracies, and ideological dogmatism.
